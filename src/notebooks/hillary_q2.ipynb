{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = pd.read_csv('../../data_q2/q2-ucsd-cat-map.csv')\n",
    "consumer = pd.read_parquet('../../data_q2/q2-ucsd-consDF.pqt')\n",
    "acct = pd.read_parquet('../../data_q2/q2-ucsd-acctDF.pqt')\n",
    "transactions = pd.read_parquet('../../data_q2/q2-ucsd-trxnDF.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories = pd.read_csv('../../data_q2/q2-ucsd-cat-map.csv')\n",
    "# consumer = pd.read_parquet('../../data_q2/q2-ucsd-consDF.pqt')\n",
    "# acct = pd.read_parquet(\"../../data_q2/q2-ucsd-acctIDF.pqt\")\n",
    "# transactions = pd.read_parquet(\"../../data_q2/q2-ucsd-trxnDF.pqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>evaluation_date</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>DQ_TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>726.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>626.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>680.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>734.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>676.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prism_consumer_id evaluation_date  credit_score  DQ_TARGET\n",
       "0                 0      2021-09-01         726.0        0.0\n",
       "1                 1      2021-07-01         626.0        0.0\n",
       "2                 2      2021-05-01         680.0        0.0\n",
       "3                 3      2021-03-01         734.0        0.0\n",
       "4                 4      2021-10-01         676.0        0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consumer.groupby('DQ_TARGET').count() #10994 0.0 vs 1006 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_transaction_id</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>credit_or_debit</th>\n",
       "      <th>posted_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3023</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2021-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3023</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>481.56</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2021-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3023</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2021-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3023</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2021-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3023</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.06</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2021-07-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prism_consumer_id prism_transaction_id  category  amount credit_or_debit  \\\n",
       "0              3023                    0         4    0.05          CREDIT   \n",
       "1              3023                    1        12  481.56          CREDIT   \n",
       "2              3023                    2         4    0.05          CREDIT   \n",
       "3              3023                    3         4    0.07          CREDIT   \n",
       "4              3023                    4         4    0.06          CREDIT   \n",
       "\n",
       "  posted_date  \n",
       "0  2021-04-16  \n",
       "1  2021-04-30  \n",
       "2  2021-05-16  \n",
       "3  2021-06-16  \n",
       "4  2021-07-16  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SELF_TRANSFER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>EXTERNAL_TRANSFER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DEPOSIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PAYCHECK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MISCELLANEOUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>PAYCHECK_PLACEHOLDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>REFUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>INVESTMENT_INCOME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>OTHER_BENEFITS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>UNEMPLOYMENT_BENEFITS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>SMALL_DOLLAR_ADVANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>TAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>LOAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>INSURANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>UNCATEGORIZED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>GROCERIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>ATM_CASH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>TRAVEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>ESSENTIAL_SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>ACCOUNT_FEES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>HOME_IMPROVEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>OVERDRAFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>CREDIT_CARD_PAYMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>HEALTHCARE_MEDICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>PETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>EDUCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>GIFTS_DONATIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>BILLS_UTILITIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>MORTGAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>CHILD_DEPENDENTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>RENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>BNPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>AUTO_LOAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>BANKING_CATCH_ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>DEBT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>FITNESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>TRANSPORATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>LEGAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>GOVERNMENT_SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>RISK_CATCH_ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>RTO_LTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>INVESTMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>GAMBLING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>CORPORATE_PAYMENTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>TIME_OR_STUFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>PENSION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category_id               category\n",
       "0             0          SELF_TRANSFER\n",
       "1             1      EXTERNAL_TRANSFER\n",
       "2             2                DEPOSIT\n",
       "3             3               PAYCHECK\n",
       "4             4          MISCELLANEOUS\n",
       "5             5   PAYCHECK_PLACEHOLDER\n",
       "6             6                 REFUND\n",
       "7             7      INVESTMENT_INCOME\n",
       "8             8         OTHER_BENEFITS\n",
       "9             9  UNEMPLOYMENT_BENEFITS\n",
       "10           10   SMALL_DOLLAR_ADVANCE\n",
       "11           11                    TAX\n",
       "12           12                   LOAN\n",
       "13           13              INSURANCE\n",
       "14           14     FOOD_AND_BEVERAGES\n",
       "15           15          UNCATEGORIZED\n",
       "16           16    GENERAL_MERCHANDISE\n",
       "17           17             AUTOMOTIVE\n",
       "18           18              GROCERIES\n",
       "19           19               ATM_CASH\n",
       "20           20          ENTERTAINMENT\n",
       "21           21                 TRAVEL\n",
       "22           22     ESSENTIAL_SERVICES\n",
       "23           23           ACCOUNT_FEES\n",
       "24           24       HOME_IMPROVEMENT\n",
       "25           25              OVERDRAFT\n",
       "26           26    CREDIT_CARD_PAYMENT\n",
       "27           27     HEALTHCARE_MEDICAL\n",
       "28           28                   PETS\n",
       "29           29              EDUCATION\n",
       "30           30        GIFTS_DONATIONS\n",
       "31           31        BILLS_UTILITIES\n",
       "32           32               MORTGAGE\n",
       "33           33       CHILD_DEPENDENTS\n",
       "34           34                   RENT\n",
       "35           35                   BNPL\n",
       "36           36              AUTO_LOAN\n",
       "37           37      BANKING_CATCH_ALL\n",
       "38           38                   DEBT\n",
       "39           39                FITNESS\n",
       "40           40          TRANSPORATION\n",
       "41           41                  LEGAL\n",
       "42           42    GOVERNMENT_SERVICES\n",
       "43           43         RISK_CATCH_ALL\n",
       "44           44                RTO_LTO\n",
       "45           45             INVESTMENT\n",
       "46           46               GAMBLING\n",
       "47           47     CORPORATE_PAYMENTS\n",
       "48           48          TIME_OR_STUFF\n",
       "49           49                PENSION"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_account_id</th>\n",
       "      <th>account_type</th>\n",
       "      <th>balance_date</th>\n",
       "      <th>balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3023</td>\n",
       "      <td>0</td>\n",
       "      <td>SAVINGS</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>90.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3023</td>\n",
       "      <td>1</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>225.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4416</td>\n",
       "      <td>2</td>\n",
       "      <td>SAVINGS</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>15157.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4416</td>\n",
       "      <td>3</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>66.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4227</td>\n",
       "      <td>4</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>7042.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prism_consumer_id prism_account_id account_type balance_date   balance\n",
       "0              3023                0      SAVINGS   2021-08-31     90.57\n",
       "1              3023                1     CHECKING   2021-08-31    225.95\n",
       "2              4416                2      SAVINGS   2022-03-31  15157.17\n",
       "3              4416                3     CHECKING   2022-03-31     66.42\n",
       "4              4227                4     CHECKING   2021-07-31   7042.90"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13009"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acct['prism_consumer_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3302.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>824.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2655.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>95.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>252.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>611.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-862.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-9.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13009 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   balance\n",
       "prism_consumer_id         \n",
       "0                   320.37\n",
       "1                  3302.42\n",
       "10                  824.24\n",
       "100                2655.47\n",
       "1000                 95.25\n",
       "...                    ...\n",
       "9995                  0.00\n",
       "9996                252.67\n",
       "9997                611.28\n",
       "9998               -862.99\n",
       "9999                 -9.02\n",
       "\n",
       "[13009 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge \n",
    "acct['account_type'].unique()\n",
    "\n",
    "# most important account_types: ['CHECKING', 'SAVINGS', 'CREDIT CARD', 'LOAN]\n",
    "# most_important_accounts = ['CHECKING', 'SAVINGS', 'CREDIT CARD', 'LOAN']\n",
    "acctDF = acct.copy()\n",
    "total_balance = acctDF.groupby('prism_consumer_id')['balance'].sum()\n",
    "total_balance\n",
    "\n",
    "pd.DataFrame(total_balance) #get total balance for each consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>evaluation_date</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>DQ_TARGET</th>\n",
       "      <th>balance</th>\n",
       "      <th>std_credit</th>\n",
       "      <th>std_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>726.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.37</td>\n",
       "      <td>0.846851</td>\n",
       "      <td>-0.146222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>626.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3302.42</td>\n",
       "      <td>-0.459894</td>\n",
       "      <td>-0.090027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>654.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>824.24</td>\n",
       "      <td>-0.094005</td>\n",
       "      <td>-0.136727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2655.47</td>\n",
       "      <td>1.160470</td>\n",
       "      <td>-0.102219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.25</td>\n",
       "      <td>1.238874</td>\n",
       "      <td>-0.150464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>9995</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>578.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.087132</td>\n",
       "      <td>-0.152259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>9996</td>\n",
       "      <td>2023-10-11</td>\n",
       "      <td>610.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252.67</td>\n",
       "      <td>-0.668973</td>\n",
       "      <td>-0.147498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>9997</td>\n",
       "      <td>2023-05-25</td>\n",
       "      <td>675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>611.28</td>\n",
       "      <td>0.180411</td>\n",
       "      <td>-0.140740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>9998</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>534.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-862.99</td>\n",
       "      <td>-1.662099</td>\n",
       "      <td>-0.168522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>9999</td>\n",
       "      <td>2023-08-09</td>\n",
       "      <td>663.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.02</td>\n",
       "      <td>0.023602</td>\n",
       "      <td>-0.152429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prism_consumer_id evaluation_date  credit_score  DQ_TARGET  balance  \\\n",
       "0                     0      2021-09-01         726.0        0.0   320.37   \n",
       "1                     1      2021-07-01         626.0        0.0  3302.42   \n",
       "2                    10      2022-02-01         654.0        0.0   824.24   \n",
       "3                   100      2021-12-01         750.0        0.0  2655.47   \n",
       "4                  1000      2021-03-01         756.0        0.0    95.25   \n",
       "...                 ...             ...           ...        ...      ...   \n",
       "14995              9995      2023-03-02         578.0        NaN     0.00   \n",
       "14996              9996      2023-10-11         610.0        NaN   252.67   \n",
       "14997              9997      2023-05-25         675.0        NaN   611.28   \n",
       "14998              9998      2023-11-02         534.0        NaN  -862.99   \n",
       "14999              9999      2023-08-09         663.0        NaN    -9.02   \n",
       "\n",
       "       std_credit  std_balance  \n",
       "0        0.846851    -0.146222  \n",
       "1       -0.459894    -0.090027  \n",
       "2       -0.094005    -0.136727  \n",
       "3        1.160470    -0.102219  \n",
       "4        1.238874    -0.150464  \n",
       "...           ...          ...  \n",
       "14995   -1.087132    -0.152259  \n",
       "14996   -0.668973    -0.147498  \n",
       "14997    0.180411    -0.140740  \n",
       "14998   -1.662099    -0.168522  \n",
       "14999    0.023602    -0.152429  \n",
       "\n",
       "[15000 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer_balance = consumer.merge(pd.DataFrame(total_balance), on = 'prism_consumer_id', how = 'outer')\n",
    "consumer_balance['std_credit'] = (consumer_balance['credit_score'] - consumer_balance['credit_score'].mean()) / consumer_balance['credit_score'].std()\n",
    "consumer_balance[\"std_balance\"] = (\n",
    "    consumer_balance[\"balance\"] - consumer_balance[\"balance\"].mean()\n",
    "    ) / consumer_balance[\"balance\"].std()\n",
    "consumer_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(11869) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from xgboost) (1.14.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "# !pip uninstall xgboost -y\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(11870) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lightgbm) (1.14.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "4.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "print(lgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "\n",
    "def run_classification(\n",
    "    feature_column, target_column, dataset, test_size=0.2, random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Run Logistic Regression and Random Forest Classification on a dataset.\n",
    "\n",
    "    Parameters:\n",
    "        feature_column (list): List of columns that can be used as features.\n",
    "        target_column (str): The name of the target column.\n",
    "        dataset (pd.DataFrame): The dataset containing the features and target.\n",
    "        test_size (float): Proportion of the dataset to include in the test split (default 0.3).\n",
    "        random_state (int): Random seed for reproducibility (default 42).\n",
    "\n",
    "    Returns:\n",
    "        None: Prints the classification reports for both models.\n",
    "    \"\"\"\n",
    "    warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)\n",
    "\n",
    "    # Drop NaN values and shuffle the dataset\n",
    "    dataset = dataset.dropna()\n",
    "    dataset = dataset.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    # Define features and target\n",
    "    X = dataset[feature_column]\n",
    "    y = dataset[target_column]\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # balance the dataset\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_bal, y_train_bal = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Logistic Regression\n",
    "    log_model = LogisticRegression(class_weight = 'balanced')\n",
    "    log_model.fit(X_train_bal, y_train_bal)\n",
    "    log_y_pred = log_model.predict(X_test)\n",
    "    print(f\"Logistic Regression for {feature_column}\")\n",
    "    print(classification_report(y_test, log_y_pred))\n",
    "\n",
    "    # Random Forest Classification\n",
    "    rfc_model = RandomForestClassifier(random_state=random_state)\n",
    "    rfc_model.fit(X_train_bal, y_train_bal)\n",
    "    rfc_y_pred = rfc_model.predict(X_test)\n",
    "    print(f\"\\nRandom Forest Classification for {feature_column}\")\n",
    "    print(classification_report(y_test, rfc_y_pred))\n",
    "\n",
    "    # Light GBM \n",
    "    lgb_model = lgb.LGBMClassifier()\n",
    "    lgb_model.fit(X_train_bal, y_train_bal)\n",
    "    lgb_y_pred = lgb_model.predict(X_test)\n",
    "    print(f\"\\nLGB Model Classification for {feature_column}\")\n",
    "    print(classification_report(y_test, lgb_y_pred))\n",
    "\n",
    "    # SVC Model\n",
    "    svc_model = SVC(probability=True, random_state=random_state)\n",
    "    svc_model.fit(X_train_bal, y_train_bal)\n",
    "    svc_y_pred = svc_model.predict(X_test)\n",
    "    print(f\"\\nSVM Classification for {feature_column}\")\n",
    "    print(classification_report(y_test, svc_y_pred))\n",
    "\n",
    "    # XGB Model\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        scale_pos_weight=len(y_train) / y_train.sum()\n",
    "        )\n",
    "    xgb_model.fit(X_train_bal, y_train_bal)\n",
    "    xgb_y_pred = xgb_model.predict(X_test)\n",
    "    print(\"\\nXGBoost:\")\n",
    "    print(classification_report(y_test, xgb_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added ROC AUC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "\n",
    "def run_classification2(\n",
    "    feature_column, target_column, dataset, test_size=0.2, random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Run Logistic Regression, Random Forest, LightGBM, SVM, and XGBoost Classification on a dataset.\n",
    "    Includes ROC-AUC evaluation for all models.\n",
    "\n",
    "    Parameters:\n",
    "        feature_column (list): List of columns that can be used as features.\n",
    "        target_column (str): The name of the target column.\n",
    "        dataset (pd.DataFrame): The dataset containing the features and target.\n",
    "        test_size (float): Proportion of the dataset to include in the test split (default 0.2).\n",
    "        random_state (int): Random seed for reproducibility (default 42).\n",
    "\n",
    "    Returns:\n",
    "        None: Prints the classification reports and ROC-AUC scores for all models.\n",
    "    \"\"\"\n",
    "    warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)\n",
    "\n",
    "    # Drop NaN values and shuffle the dataset\n",
    "    dataset = dataset.dropna()\n",
    "    dataset = dataset.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    # Define features and target\n",
    "    X = dataset[feature_column]\n",
    "    y = dataset[target_column]\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Balance the dataset using SMOTE\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_bal, y_train_bal = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Logistic Regression\n",
    "    log_model = LogisticRegression(class_weight='balanced')\n",
    "    log_model.fit(X_train_bal, y_train_bal)\n",
    "    log_y_pred = log_model.predict(X_test)\n",
    "    log_y_proba = log_model.predict_proba(X_test)[:, 1]\n",
    "    print(f\"Logistic Regression for {feature_column}\")\n",
    "    print(classification_report(y_test, log_y_pred))\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_test, log_y_proba):.3f}\")\n",
    "\n",
    "    # Random Forest Classification\n",
    "    rfc_model = RandomForestClassifier(random_state=random_state)\n",
    "    rfc_model.fit(X_train_bal, y_train_bal)\n",
    "    rfc_y_pred = rfc_model.predict(X_test)\n",
    "    rfc_y_proba = rfc_model.predict_proba(X_test)[:, 1]\n",
    "    print(f\"\\nRandom Forest Classification for {feature_column}\")\n",
    "    print(classification_report(y_test, rfc_y_pred))\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_test, rfc_y_proba):.3f}\")\n",
    "\n",
    "    # LightGBM\n",
    "    lgb_model = lgb.LGBMClassifier()\n",
    "    lgb_model.fit(X_train_bal, y_train_bal)\n",
    "    lgb_y_pred = lgb_model.predict(X_test)\n",
    "    lgb_y_proba = lgb_model.predict_proba(X_test)[:, 1]\n",
    "    print(f\"\\nLightGBM Classification for {feature_column}\")\n",
    "    print(classification_report(y_test, lgb_y_pred))\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_test, lgb_y_proba):.3f}\")\n",
    "\n",
    "    # SVM Classification\n",
    "    svc_model = SVC(probability=True, random_state=random_state)\n",
    "    svc_model.fit(X_train_bal, y_train_bal)\n",
    "    svc_y_pred = svc_model.predict(X_test)\n",
    "    svc_y_proba = svc_model.predict_proba(X_test)[:, 1]\n",
    "    print(f\"\\nSVM Classification for {feature_column}\")\n",
    "    print(classification_report(y_test, svc_y_pred))\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_test, svc_y_proba):.3f}\")\n",
    "\n",
    "    # XGBoost Classification\n",
    "    xgb_model = xgb.XGBClassifier(scale_pos_weight=len(y_train) / y_train.sum())\n",
    "    xgb_model.fit(X_train_bal, y_train_bal)\n",
    "    xgb_y_pred = xgb_model.predict(X_test)\n",
    "    xgb_y_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    print(f\"\\nXGBoost Classification for {feature_column}\")\n",
    "    print(classification_report(y_test, xgb_y_pred))\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_test, xgb_y_proba):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression for ['std_credit']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.74      0.83      1897\n",
      "         1.0       0.19      0.63      0.29       185\n",
      "\n",
      "    accuracy                           0.73      2082\n",
      "   macro avg       0.57      0.68      0.56      2082\n",
      "weighted avg       0.89      0.73      0.78      2082\n",
      "\n",
      "\n",
      "Random Forest Classification for ['std_credit']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.81      0.87      1897\n",
      "         1.0       0.16      0.38      0.23       185\n",
      "\n",
      "    accuracy                           0.77      2082\n",
      "   macro avg       0.55      0.60      0.55      2082\n",
      "weighted avg       0.86      0.77      0.81      2082\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 7596, number of negative: 7596\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 15192, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "LGB Model Classification for ['std_credit']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.74      0.83      1897\n",
      "         1.0       0.18      0.60      0.28       185\n",
      "\n",
      "    accuracy                           0.72      2082\n",
      "   macro avg       0.57      0.67      0.55      2082\n",
      "weighted avg       0.88      0.72      0.78      2082\n",
      "\n",
      "\n",
      "SVM Classification for ['std_credit']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.73      0.83      1897\n",
      "         1.0       0.19      0.63      0.29       185\n",
      "\n",
      "    accuracy                           0.72      2082\n",
      "   macro avg       0.57      0.68      0.56      2082\n",
      "weighted avg       0.89      0.72      0.78      2082\n",
      "\n",
      "\n",
      "XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.21      0.35      1897\n",
      "         1.0       0.11      0.96      0.19       185\n",
      "\n",
      "    accuracy                           0.28      2082\n",
      "   macro avg       0.54      0.58      0.27      2082\n",
      "weighted avg       0.90      0.28      0.34      2082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classification([\"std_credit\"], \"DQ_TARGET\", consumer_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression for ['std_credit']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.74      0.83      1897\n",
      "         1.0       0.19      0.63      0.29       185\n",
      "\n",
      "    accuracy                           0.73      2082\n",
      "   macro avg       0.57      0.68      0.56      2082\n",
      "weighted avg       0.89      0.73      0.78      2082\n",
      "\n",
      "ROC-AUC Score: 0.750\n",
      "\n",
      "Random Forest Classification for ['std_credit']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.81      0.87      1897\n",
      "         1.0       0.16      0.38      0.23       185\n",
      "\n",
      "    accuracy                           0.77      2082\n",
      "   macro avg       0.55      0.60      0.55      2082\n",
      "weighted avg       0.86      0.77      0.81      2082\n",
      "\n",
      "ROC-AUC Score: 0.662\n",
      "[LightGBM] [Info] Number of positive: 7596, number of negative: 7596\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 15192, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "LightGBM Classification for ['std_credit']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.74      0.83      1897\n",
      "         1.0       0.18      0.60      0.28       185\n",
      "\n",
      "    accuracy                           0.72      2082\n",
      "   macro avg       0.57      0.67      0.55      2082\n",
      "weighted avg       0.88      0.72      0.78      2082\n",
      "\n",
      "ROC-AUC Score: 0.724\n",
      "\n",
      "SVM Classification for ['std_credit']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.73      0.83      1897\n",
      "         1.0       0.19      0.63      0.29       185\n",
      "\n",
      "    accuracy                           0.72      2082\n",
      "   macro avg       0.57      0.68      0.56      2082\n",
      "weighted avg       0.89      0.72      0.78      2082\n",
      "\n",
      "ROC-AUC Score: 0.727\n",
      "\n",
      "XGBoost Classification for ['std_credit']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.21      0.35      1897\n",
      "         1.0       0.11      0.96      0.19       185\n",
      "\n",
      "    accuracy                           0.28      2082\n",
      "   macro avg       0.54      0.58      0.27      2082\n",
      "weighted avg       0.90      0.28      0.34      2082\n",
      "\n",
      "ROC-AUC Score: 0.718\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "run_classification2([\"std_credit\"], \"DQ_TARGET\", consumer_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression for ['std_balance']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.36      0.52      1897\n",
      "         1.0       0.11      0.85      0.20       185\n",
      "\n",
      "    accuracy                           0.40      2082\n",
      "   macro avg       0.54      0.61      0.36      2082\n",
      "weighted avg       0.89      0.40      0.49      2082\n",
      "\n",
      "\n",
      "Random Forest Classification for ['std_balance']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.68      0.79      1897\n",
      "         1.0       0.11      0.41      0.18       185\n",
      "\n",
      "    accuracy                           0.66      2082\n",
      "   macro avg       0.52      0.55      0.48      2082\n",
      "weighted avg       0.85      0.66      0.73      2082\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 7596, number of negative: 7596\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 15192, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "LGB Model Classification for ['std_balance']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.67      0.78      1897\n",
      "         1.0       0.14      0.56      0.23       185\n",
      "\n",
      "    accuracy                           0.66      2082\n",
      "   macro avg       0.54      0.61      0.50      2082\n",
      "weighted avg       0.87      0.66      0.73      2082\n",
      "\n",
      "\n",
      "SVM Classification for ['std_balance']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.41      0.57      1897\n",
      "         1.0       0.12      0.83      0.21       185\n",
      "\n",
      "    accuracy                           0.44      2082\n",
      "   macro avg       0.54      0.62      0.39      2082\n",
      "weighted avg       0.89      0.44      0.54      2082\n",
      "\n",
      "\n",
      "XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.12      0.22      1897\n",
      "         1.0       0.10      0.95      0.17       185\n",
      "\n",
      "    accuracy                           0.20      2082\n",
      "   macro avg       0.53      0.54      0.20      2082\n",
      "weighted avg       0.89      0.20      0.22      2082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage:  #features, target, dataframe\n",
    "run_classification([\"std_balance\"], \"DQ_TARGET\", consumer_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression for ['std_balance']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.36      0.52      1897\n",
      "         1.0       0.11      0.85      0.20       185\n",
      "\n",
      "    accuracy                           0.40      2082\n",
      "   macro avg       0.54      0.61      0.36      2082\n",
      "weighted avg       0.89      0.40      0.49      2082\n",
      "\n",
      "ROC-AUC Score: 0.701\n",
      "\n",
      "Random Forest Classification for ['std_balance']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.68      0.79      1897\n",
      "         1.0       0.11      0.41      0.18       185\n",
      "\n",
      "    accuracy                           0.66      2082\n",
      "   macro avg       0.52      0.55      0.48      2082\n",
      "weighted avg       0.85      0.66      0.73      2082\n",
      "\n",
      "ROC-AUC Score: 0.589\n",
      "[LightGBM] [Info] Number of positive: 7596, number of negative: 7596\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 15192, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "LightGBM Classification for ['std_balance']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.67      0.78      1897\n",
      "         1.0       0.14      0.56      0.23       185\n",
      "\n",
      "    accuracy                           0.66      2082\n",
      "   macro avg       0.54      0.61      0.50      2082\n",
      "weighted avg       0.87      0.66      0.73      2082\n",
      "\n",
      "ROC-AUC Score: 0.661\n",
      "\n",
      "SVM Classification for ['std_balance']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.41      0.57      1897\n",
      "         1.0       0.12      0.83      0.21       185\n",
      "\n",
      "    accuracy                           0.44      2082\n",
      "   macro avg       0.54      0.62      0.39      2082\n",
      "weighted avg       0.89      0.44      0.54      2082\n",
      "\n",
      "ROC-AUC Score: 0.704\n",
      "\n",
      "XGBoost Classification for ['std_balance']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.12      0.22      1897\n",
      "         1.0       0.10      0.95      0.17       185\n",
      "\n",
      "    accuracy                           0.20      2082\n",
      "   macro avg       0.53      0.54      0.20      2082\n",
      "weighted avg       0.89      0.20      0.22      2082\n",
      "\n",
      "ROC-AUC Score: 0.672\n"
     ]
    }
   ],
   "source": [
    "run_classification2([\"std_balance\"], \"DQ_TARGET\", consumer_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression for ['total_credit', 'total_debit']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.36      0.52      2784\n",
      "         1.0       0.09      0.79      0.16       216\n",
      "\n",
      "    accuracy                           0.39      3000\n",
      "   macro avg       0.52      0.57      0.34      3000\n",
      "weighted avg       0.89      0.39      0.49      3000\n",
      "\n",
      "ROC-AUC Score: 0.604\n",
      "\n",
      "Random Forest Classification for ['total_credit', 'total_debit']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.76      0.84      2784\n",
      "         1.0       0.11      0.39      0.17       216\n",
      "\n",
      "    accuracy                           0.73      3000\n",
      "   macro avg       0.53      0.57      0.51      3000\n",
      "weighted avg       0.88      0.73      0.79      3000\n",
      "\n",
      "ROC-AUC Score: 0.600\n",
      "[LightGBM] [Info] Number of positive: 11210, number of negative: 11210\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 22420, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "LightGBM Classification for ['total_credit', 'total_debit']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.67      0.78      2784\n",
      "         1.0       0.11      0.51      0.18       216\n",
      "\n",
      "    accuracy                           0.66      3000\n",
      "   macro avg       0.53      0.59      0.48      3000\n",
      "weighted avg       0.89      0.66      0.74      3000\n",
      "\n",
      "ROC-AUC Score: 0.639\n",
      "\n",
      "SVM Classification for ['total_credit', 'total_debit']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.56      0.70      2784\n",
      "         1.0       0.10      0.60      0.16       216\n",
      "\n",
      "    accuracy                           0.56      3000\n",
      "   macro avg       0.52      0.58      0.43      3000\n",
      "weighted avg       0.89      0.56      0.66      3000\n",
      "\n",
      "ROC-AUC Score: 0.606\n",
      "\n",
      "XGBoost Classification for ['total_credit', 'total_debit']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.32      0.47      2784\n",
      "         1.0       0.09      0.83      0.16       216\n",
      "\n",
      "    accuracy                           0.35      3000\n",
      "   macro avg       0.52      0.57      0.32      3000\n",
      "weighted avg       0.90      0.35      0.45      3000\n",
      "\n",
      "ROC-AUC Score: 0.633\n"
     ]
    }
   ],
   "source": [
    "#NEW FEATURES: credit and debit\n",
    "\n",
    "credit_transactions = transactions[transactions['credit_or_debit'] == 'CREDIT']\n",
    "debit_transactions = transactions[transactions['credit_or_debit'] == 'DEBIT']\n",
    "\n",
    "credit_features = credit_transactions.groupby('prism_consumer_id').agg(\n",
    "    total_credit=('amount', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "debit_features = debit_transactions.groupby('prism_consumer_id').agg(\n",
    "    total_debit=('amount', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "credit_debit_features = credit_features.merge(debit_features, on='prism_consumer_id', how='outer').fillna(0)\n",
    "consumer_features = consumer.merge(credit_debit_features, on='prism_consumer_id', how='left').fillna(0)\n",
    "\n",
    "run_classification2(['total_credit', 'total_debit'], 'DQ_TARGET', consumer_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>total_credit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14386.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24903.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>20576.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>35236.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>78353.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14471</th>\n",
       "      <td>9995</td>\n",
       "      <td>16925.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14472</th>\n",
       "      <td>9996</td>\n",
       "      <td>1200.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14473</th>\n",
       "      <td>9997</td>\n",
       "      <td>17206.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14474</th>\n",
       "      <td>9998</td>\n",
       "      <td>14566.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14475</th>\n",
       "      <td>9999</td>\n",
       "      <td>31777.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14476 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prism_consumer_id  total_credit\n",
       "0                     0      14386.82\n",
       "1                     1      24903.80\n",
       "2                    10      20576.56\n",
       "3                   100      35236.84\n",
       "4                  1000      78353.07\n",
       "...                 ...           ...\n",
       "14471              9995      16925.84\n",
       "14472              9996       1200.03\n",
       "14473              9997      17206.11\n",
       "14474              9998      14566.37\n",
       "14475              9999      31777.82\n",
       "\n",
       "[14476 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQ_TARGET\n",
       "0.0    10994\n",
       "1.0     1006\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer_balance['DQ_TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prism_consumer_id       0\n",
       "evaluation_date         0\n",
       "credit_score            0\n",
       "DQ_TARGET            3000\n",
       "balance              1991\n",
       "std_credit              0\n",
       "std_balance          1991\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer_balance.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQ_TARGET\n",
       "0.0    9493\n",
       "1.0     915\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = consumer_balance.dropna()\n",
    "new_data['DQ_TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/mwcq9vv51rscfd92n_2xs8vc0000gn/T/ipykernel_11723/2405563956.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  transactions_with_balances = transactions.groupby('prism_consumer_id').apply(calculate_balances)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_transaction_id</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>credit_or_debit</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>days_since</th>\n",
       "      <th>calculated_balance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>136802</th>\n",
       "      <td>0</td>\n",
       "      <td>136738</td>\n",
       "      <td>14</td>\n",
       "      <td>27.62</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>1147</td>\n",
       "      <td>-27.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136767</th>\n",
       "      <td>0</td>\n",
       "      <td>136703</td>\n",
       "      <td>11</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>1146</td>\n",
       "      <td>1372.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136803</th>\n",
       "      <td>0</td>\n",
       "      <td>136739</td>\n",
       "      <td>39</td>\n",
       "      <td>25.10</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>1146</td>\n",
       "      <td>1347.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136804</th>\n",
       "      <td>0</td>\n",
       "      <td>136740</td>\n",
       "      <td>37</td>\n",
       "      <td>500.00</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>1146</td>\n",
       "      <td>847.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136805</th>\n",
       "      <td>0</td>\n",
       "      <td>136741</td>\n",
       "      <td>14</td>\n",
       "      <td>25.00</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2021-03-18</td>\n",
       "      <td>1145</td>\n",
       "      <td>822.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         prism_consumer_id prism_transaction_id  category  \\\n",
       "prism_consumer_id                                                           \n",
       "0                 136802                 0               136738        14   \n",
       "                  136767                 0               136703        11   \n",
       "                  136803                 0               136739        39   \n",
       "                  136804                 0               136740        37   \n",
       "                  136805                 0               136741        14   \n",
       "\n",
       "                           amount credit_or_debit posted_date  days_since  \\\n",
       "prism_consumer_id                                                           \n",
       "0                 136802    27.62           DEBIT  2021-03-16        1147   \n",
       "                  136767  1400.00          CREDIT  2021-03-17        1146   \n",
       "                  136803    25.10           DEBIT  2021-03-17        1146   \n",
       "                  136804   500.00           DEBIT  2021-03-17        1146   \n",
       "                  136805    25.00           DEBIT  2021-03-18        1145   \n",
       "\n",
       "                          calculated_balance  \n",
       "prism_consumer_id                             \n",
       "0                 136802              -27.62  \n",
       "                  136767             1372.38  \n",
       "                  136803             1347.28  \n",
       "                  136804              847.28  \n",
       "                  136805              822.28  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "transactions['posted_date'] = pd.to_datetime(transactions['posted_date'])\n",
    "\n",
    "# sort transactions by consumer ID and date\n",
    "transactions = transactions.sort_values(by=['prism_consumer_id', 'posted_date'])\n",
    "\n",
    "def calculate_balances(group):\n",
    "    balance = 0\n",
    "    balances = []  # cumulative balances\n",
    "    for _, row in group.iterrows():\n",
    "        if row['credit_or_debit'] == 'CREDIT':\n",
    "            balance += row['amount']  # add for CREDIT\n",
    "        elif row['credit_or_debit'] == 'DEBIT':\n",
    "            balance -= row['amount']  # subtract for DEBIT\n",
    "        balances.append(balance)\n",
    "    group['calculated_balance'] = balances\n",
    "    return group\n",
    "\n",
    "transactions_with_balances = transactions.groupby('prism_consumer_id').apply(calculate_balances)\n",
    "\n",
    "transactions_with_balances.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/mwcq9vv51rscfd92n_2xs8vc0000gn/T/ipykernel_11723/990600752.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  transactions_with_balances = transactions.groupby('prism_consumer_id').apply(calculate_balances).reset_index(drop=True)\n",
      "/var/folders/4d/mwcq9vv51rscfd92n_2xs8vc0000gn/T/ipykernel_11723/990600752.py:32: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  transaction_features = transactions_with_balances.groupby('prism_consumer_id').apply(lambda group: {\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  prism_consumer_id evaluation_date  credit_score  DQ_TARGET  total_credit  \\\n",
      "0                 0      2021-09-01         726.0        0.0      14386.82   \n",
      "1                 1      2021-07-01         626.0        0.0      24903.80   \n",
      "2                 2      2021-05-01         680.0        0.0      22764.71   \n",
      "3                 3      2021-03-01         734.0        0.0      22641.25   \n",
      "4                 4      2021-10-01         676.0        0.0      14966.11   \n",
      "\n",
      "   total_debit  spending_30d  spending_90d  spending_180d  spending_365d  ...  \\\n",
      "0     14908.41           0.0           0.0            0.0            0.0  ...   \n",
      "1     23098.37           0.0           0.0            0.0            0.0  ...   \n",
      "2     22334.58           0.0           0.0            0.0            0.0  ...   \n",
      "3     19846.01           0.0           0.0            0.0            0.0  ...   \n",
      "4     17509.71           0.0           0.0            0.0            0.0  ...   \n",
      "\n",
      "   category_43_spending  category_49_spending  category_44_spending  \\\n",
      "0                   0.0                   0.0                   0.0   \n",
      "1                   0.0                   0.0                   0.0   \n",
      "2                   0.0                   0.0                   0.0   \n",
      "3                   0.0                   0.0                   0.0   \n",
      "4                   0.0                   0.0                   0.0   \n",
      "\n",
      "   category_47_spending  max_balance  min_balance  mean_balance  std_balance  \\\n",
      "0                   0.0      2453.57     -1313.77     14.041691   987.249970   \n",
      "1                   0.0      4105.85      -214.49   1711.022516  1194.401621   \n",
      "2                   0.0      6741.39      -888.86   2221.914063  2505.160972   \n",
      "3                   0.0      4519.54     -3767.46   -389.950148  1943.047822   \n",
      "4                   0.0       362.83     -2543.60  -1072.100915   657.585058   \n",
      "\n",
      "   negative_balance_count  account_duration_days  \n",
      "0                   237.0                 1147.0  \n",
      "1                    27.0                 1207.0  \n",
      "2                    60.0                 1279.0  \n",
      "3                   151.0                 1321.0  \n",
      "4                   294.0                 1387.0  \n",
      "\n",
      "[5 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "# create new features\n",
    "\n",
    "transactions['posted_date'] = pd.to_datetime(transactions['posted_date'])\n",
    "\n",
    "transactions = transactions.sort_values(by=['prism_consumer_id', 'posted_date'])\n",
    "\n",
    "def calculate_balances(group):\n",
    "    balance = 0\n",
    "    balances = []\n",
    "    for _, row in group.iterrows():\n",
    "        if row['credit_or_debit'] == 'CREDIT':\n",
    "            balance += row['amount']\n",
    "        elif row['credit_or_debit'] == 'DEBIT':\n",
    "            balance -= row['amount']\n",
    "        balances.append(balance)\n",
    "    group['calculated_balance'] = balances\n",
    "    return group\n",
    "\n",
    "transactions_with_balances = transactions.groupby('prism_consumer_id').apply(calculate_balances).reset_index(drop=True)\n",
    "\n",
    "transactions_with_balances['days_since'] = (transactions_with_balances['posted_date'].max() - transactions_with_balances['posted_date']).dt.days\n",
    "\n",
    "# time windows\n",
    "time_windows = [30, 90, 180, 365, 730, 1095]  # 1 month, 3 months, 6 months, 1 year, 2 years, 3 years\n",
    "\n",
    "# groupby prism_consumer_id and calculate features\n",
    "transaction_features = transactions_with_balances.groupby('prism_consumer_id').apply(lambda group: {\n",
    "    # total credit and debit\n",
    "    'total_credit': group[group['credit_or_debit'] == 'CREDIT']['amount'].sum(),\n",
    "    'total_debit': group[group['credit_or_debit'] == 'DEBIT']['amount'].sum(),\n",
    "    \n",
    "    # spending in different time windows\n",
    "    **{f'spending_{tw}d': group[group['days_since'] <= tw]['amount'].sum() for tw in time_windows},\n",
    "    \n",
    "    # spending based on categories (ex. 49 categories)\n",
    "    **{f'category_{cat}_spending': group[group['category'] == cat]['amount'].sum() for cat in transactions_with_balances['category'].unique()},\n",
    "    \n",
    "    # balance-based features\n",
    "    'max_balance': group['calculated_balance'].max(),\n",
    "    'min_balance': group['calculated_balance'].min(),\n",
    "    'mean_balance': group['calculated_balance'].mean(),\n",
    "    'std_balance': group['calculated_balance'].std(),\n",
    "    \n",
    "    # number of times balance was negative\n",
    "    'negative_balance_count': (group['calculated_balance'] < 0).sum(),\n",
    "    \n",
    "    # duration of account (days)\n",
    "    'account_duration_days': group['days_since'].max()\n",
    "}).apply(pd.Series).reset_index()\n",
    "\n",
    "# merge transaction features with consumer data\n",
    "consumer_features = consumer.merge(transaction_features, on='prism_consumer_id', how='left')\n",
    "\n",
    "# fill NaN values with 0 (ex. consumers with no transactions)\n",
    "consumer_features.fillna(0, inplace=True)\n",
    "\n",
    "print(consumer_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing Single Feature: total_credit ---\n",
      "Logistic Regression ROC-AUC Score: 0.603\n",
      "Random Forest ROC-AUC Score: 0.543\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.563\n",
      "XGBoost ROC-AUC Score: 0.552\n",
      "\n",
      "\n",
      "--- Testing Single Feature: total_debit ---\n",
      "Logistic Regression ROC-AUC Score: 0.589\n",
      "Random Forest ROC-AUC Score: 0.552\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.561\n",
      "XGBoost ROC-AUC Score: 0.550\n",
      "\n",
      "\n",
      "--- Testing Single Feature: max_balance ---\n",
      "Logistic Regression ROC-AUC Score: 0.587\n",
      "Random Forest ROC-AUC Score: 0.506\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.488\n",
      "XGBoost ROC-AUC Score: 0.474\n",
      "\n",
      "\n",
      "--- Testing Single Feature: min_balance ---\n",
      "Logistic Regression ROC-AUC Score: 0.574\n",
      "Random Forest ROC-AUC Score: 0.553\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.602\n",
      "XGBoost ROC-AUC Score: 0.603\n",
      "\n",
      "\n",
      "--- Testing Single Feature: mean_balance ---\n",
      "Logistic Regression ROC-AUC Score: 0.551\n",
      "Random Forest ROC-AUC Score: 0.529\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.565\n",
      "XGBoost ROC-AUC Score: 0.561\n",
      "\n",
      "\n",
      "--- Testing Single Feature: std_balance ---\n",
      "Logistic Regression ROC-AUC Score: 0.611\n",
      "Random Forest ROC-AUC Score: 0.553\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.565\n",
      "XGBoost ROC-AUC Score: 0.563\n",
      "\n",
      "\n",
      "--- Testing Single Feature: negative_balance_count ---\n",
      "Logistic Regression ROC-AUC Score: 0.508\n",
      "Random Forest ROC-AUC Score: 0.544\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.489\n",
      "XGBoost ROC-AUC Score: 0.486\n",
      "\n",
      "\n",
      "--- Testing Single Feature: account_duration_days ---\n",
      "Logistic Regression ROC-AUC Score: 0.682\n",
      "Random Forest ROC-AUC Score: 0.598\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.670\n",
      "XGBoost ROC-AUC Score: 0.648\n",
      "\n",
      "\n",
      "--- Testing Single Feature: spending_30d ---\n",
      "Logistic Regression ROC-AUC Score: 0.500\n",
      "Random Forest ROC-AUC Score: 0.500\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "LightGBM ROC-AUC Score: 0.500\n",
      "XGBoost ROC-AUC Score: 0.500\n",
      "\n",
      "\n",
      "--- Testing Single Feature: spending_90d ---\n",
      "Logistic Regression ROC-AUC Score: 0.500\n",
      "Random Forest ROC-AUC Score: 0.500\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "LightGBM ROC-AUC Score: 0.500\n",
      "XGBoost ROC-AUC Score: 0.500\n",
      "\n",
      "\n",
      "--- Testing Single Feature: spending_180d ---\n",
      "Logistic Regression ROC-AUC Score: 0.498\n",
      "Random Forest ROC-AUC Score: 0.499\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM ROC-AUC Score: 0.501\n",
      "XGBoost ROC-AUC Score: 0.501\n",
      "\n",
      "\n",
      "--- Testing Single Feature: spending_365d ---\n",
      "Logistic Regression ROC-AUC Score: 0.596\n",
      "Random Forest ROC-AUC Score: 0.489\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.594\n",
      "XGBoost ROC-AUC Score: 0.586\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_14_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.534\n",
      "Random Forest ROC-AUC Score: 0.477\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.531\n",
      "XGBoost ROC-AUC Score: 0.523\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_11_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.545\n",
      "Random Forest ROC-AUC Score: 0.523\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.537\n",
      "XGBoost ROC-AUC Score: 0.528\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_39_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.534\n",
      "Random Forest ROC-AUC Score: 0.527\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.536\n",
      "XGBoost ROC-AUC Score: 0.521\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_37_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.512\n",
      "Random Forest ROC-AUC Score: 0.507\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.519\n",
      "XGBoost ROC-AUC Score: 0.500\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_17_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.501\n",
      "Random Forest ROC-AUC Score: 0.481\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.502\n",
      "XGBoost ROC-AUC Score: 0.517\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_4_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.521\n",
      "Random Forest ROC-AUC Score: 0.504\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.493\n",
      "XGBoost ROC-AUC Score: 0.501\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_3_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.568\n",
      "Random Forest ROC-AUC Score: 0.525\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.546\n",
      "XGBoost ROC-AUC Score: 0.553\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_28_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.530\n",
      "Random Forest ROC-AUC Score: 0.520\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.503\n",
      "XGBoost ROC-AUC Score: 0.519\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_16_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.547\n",
      "Random Forest ROC-AUC Score: 0.516\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.519\n",
      "XGBoost ROC-AUC Score: 0.507\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_18_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.566\n",
      "Random Forest ROC-AUC Score: 0.525\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.529\n",
      "XGBoost ROC-AUC Score: 0.536\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_0_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.604\n",
      "Random Forest ROC-AUC Score: 0.538\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.586\n",
      "XGBoost ROC-AUC Score: 0.579\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_27_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.529\n",
      "Random Forest ROC-AUC Score: 0.510\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.536\n",
      "XGBoost ROC-AUC Score: 0.523\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_20_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.532\n",
      "Random Forest ROC-AUC Score: 0.478\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.501\n",
      "XGBoost ROC-AUC Score: 0.483\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_1_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.505\n",
      "Random Forest ROC-AUC Score: 0.516\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.501\n",
      "XGBoost ROC-AUC Score: 0.496\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_21_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.490\n",
      "Random Forest ROC-AUC Score: 0.479\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.515\n",
      "XGBoost ROC-AUC Score: 0.493\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_19_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.520\n",
      "Random Forest ROC-AUC Score: 0.466\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.488\n",
      "XGBoost ROC-AUC Score: 0.484\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_40_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.518\n",
      "Random Forest ROC-AUC Score: 0.520\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.475\n",
      "XGBoost ROC-AUC Score: 0.481\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_6_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.520\n",
      "Random Forest ROC-AUC Score: 0.516\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.490\n",
      "XGBoost ROC-AUC Score: 0.531\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_2_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.527\n",
      "Random Forest ROC-AUC Score: 0.517\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.517\n",
      "XGBoost ROC-AUC Score: 0.512\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_35_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.566\n",
      "Random Forest ROC-AUC Score: 0.512\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.501\n",
      "XGBoost ROC-AUC Score: 0.501\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_34_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.521\n",
      "Random Forest ROC-AUC Score: 0.506\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.529\n",
      "XGBoost ROC-AUC Score: 0.526\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_22_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.516\n",
      "Random Forest ROC-AUC Score: 0.485\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.515\n",
      "XGBoost ROC-AUC Score: 0.521\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_46_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.513\n",
      "Random Forest ROC-AUC Score: 0.493\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.498\n",
      "XGBoost ROC-AUC Score: 0.494\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_30_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.529\n",
      "Random Forest ROC-AUC Score: 0.515\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.514\n",
      "XGBoost ROC-AUC Score: 0.509\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_26_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.556\n",
      "Random Forest ROC-AUC Score: 0.524\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.527\n",
      "XGBoost ROC-AUC Score: 0.548\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_13_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.534\n",
      "Random Forest ROC-AUC Score: 0.528\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.551\n",
      "XGBoost ROC-AUC Score: 0.521\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_45_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.539\n",
      "Random Forest ROC-AUC Score: 0.521\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.522\n",
      "XGBoost ROC-AUC Score: 0.520\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_12_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.466\n",
      "Random Forest ROC-AUC Score: 0.511\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.529\n",
      "XGBoost ROC-AUC Score: 0.525\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_7_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.476\n",
      "Random Forest ROC-AUC Score: 0.524\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.530\n",
      "XGBoost ROC-AUC Score: 0.521\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_42_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.507\n",
      "Random Forest ROC-AUC Score: 0.491\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.496\n",
      "XGBoost ROC-AUC Score: 0.496\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_24_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.528\n",
      "Random Forest ROC-AUC Score: 0.532\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.514\n",
      "XGBoost ROC-AUC Score: 0.525\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_31_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.507\n",
      "Random Forest ROC-AUC Score: 0.513\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.543\n",
      "XGBoost ROC-AUC Score: 0.550\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_23_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.437\n",
      "Random Forest ROC-AUC Score: 0.527\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.550\n",
      "XGBoost ROC-AUC Score: 0.546\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_25_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.558\n",
      "Random Forest ROC-AUC Score: 0.528\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.545\n",
      "XGBoost ROC-AUC Score: 0.547\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_36_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.486\n",
      "Random Forest ROC-AUC Score: 0.510\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.529\n",
      "XGBoost ROC-AUC Score: 0.527\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_41_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.508\n",
      "Random Forest ROC-AUC Score: 0.509\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.512\n",
      "XGBoost ROC-AUC Score: 0.513\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_8_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.506\n",
      "Random Forest ROC-AUC Score: 0.504\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.498\n",
      "XGBoost ROC-AUC Score: 0.499\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_32_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.520\n",
      "Random Forest ROC-AUC Score: 0.511\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.503\n",
      "XGBoost ROC-AUC Score: 0.496\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_48_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.507\n",
      "Random Forest ROC-AUC Score: 0.505\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM ROC-AUC Score: 0.509\n",
      "XGBoost ROC-AUC Score: 0.506\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_29_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.538\n",
      "Random Forest ROC-AUC Score: 0.508\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.526\n",
      "XGBoost ROC-AUC Score: 0.520\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_38_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.492\n",
      "Random Forest ROC-AUC Score: 0.497\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.512\n",
      "XGBoost ROC-AUC Score: 0.507\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_9_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.503\n",
      "Random Forest ROC-AUC Score: 0.500\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 244\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM ROC-AUC Score: 0.499\n",
      "XGBoost ROC-AUC Score: 0.504\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_33_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.503\n",
      "Random Forest ROC-AUC Score: 0.509\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM ROC-AUC Score: 0.508\n",
      "XGBoost ROC-AUC Score: 0.502\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_43_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.501\n",
      "Random Forest ROC-AUC Score: 0.502\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM ROC-AUC Score: 0.502\n",
      "XGBoost ROC-AUC Score: 0.497\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_49_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.505\n",
      "Random Forest ROC-AUC Score: 0.500\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.498\n",
      "XGBoost ROC-AUC Score: 0.499\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_44_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.535\n",
      "Random Forest ROC-AUC Score: 0.499\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM ROC-AUC Score: 0.518\n",
      "XGBoost ROC-AUC Score: 0.523\n",
      "\n",
      "\n",
      "--- Testing Single Feature: category_47_spending ---\n",
      "Logistic Regression ROC-AUC Score: 0.503\n",
      "Random Forest ROC-AUC Score: 0.502\n",
      "[LightGBM] [Info] Number of positive: 11196, number of negative: 11196\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 37\n",
      "[LightGBM] [Info] Number of data points in the train set: 22392, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM ROC-AUC Score: 0.502\n",
      "XGBoost ROC-AUC Score: 0.501\n",
      "\n",
      "\n",
      "Top Features by ROC-AUC:\n",
      "                  feature  best_auc\n",
      "7   account_duration_days  0.681683\n",
      "5             std_balance  0.610905\n",
      "22    category_0_spending  0.604206\n",
      "3             min_balance  0.603177\n",
      "0            total_credit  0.602917\n",
      "11          spending_365d  0.596193\n",
      "1             total_debit  0.588642\n",
      "2             max_balance  0.587111\n",
      "18    category_3_spending  0.567506\n",
      "31   category_35_spending  0.566115\n"
     ]
    }
   ],
   "source": [
    "# test + store results of features\n",
    "\n",
    "results = []\n",
    "\n",
    "for feature in feature_columns:\n",
    "    print(f\"--- Testing Single Feature: {feature} ---\")\n",
    "    \n",
    "    # features (X) and target (y)\n",
    "    X = dataset[[feature]]\n",
    "    y = dataset[target_column]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # balance the training data using SMOTE\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_bal, y_train_bal = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Logistic Regression\n",
    "    log_model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "    log_model.fit(X_train_bal, y_train_bal)\n",
    "    log_y_proba = log_model.predict_proba(X_test)[:, 1]\n",
    "    log_auc = roc_auc_score(y_test, log_y_proba)\n",
    "    print(f\"Logistic Regression ROC-AUC Score: {log_auc:.3f}\")\n",
    "\n",
    "    # Random Forest\n",
    "    rfc_model = RandomForestClassifier(random_state=42)\n",
    "    rfc_model.fit(X_train_bal, y_train_bal)\n",
    "    rfc_y_proba = rfc_model.predict_proba(X_test)[:, 1]\n",
    "    rfc_auc = roc_auc_score(y_test, rfc_y_proba)\n",
    "    print(f\"Random Forest ROC-AUC Score: {rfc_auc:.3f}\")\n",
    "\n",
    "    # LightGBM\n",
    "    lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "    lgb_model.fit(X_train_bal, y_train_bal)\n",
    "    lgb_y_proba = lgb_model.predict_proba(X_test)[:, 1]\n",
    "    lgb_auc = roc_auc_score(y_test, lgb_y_proba)\n",
    "    print(f\"LightGBM ROC-AUC Score: {lgb_auc:.3f}\")\n",
    "\n",
    "    # XGBoost\n",
    "    xgb_model = xgb.XGBClassifier(scale_pos_weight=len(y_train) / y_train.sum(), random_state=42)\n",
    "    xgb_model.fit(X_train_bal, y_train_bal)\n",
    "    xgb_y_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    xgb_auc = roc_auc_score(y_test, xgb_y_proba)\n",
    "    print(f\"XGBoost ROC-AUC Score: {xgb_auc:.3f}\")\n",
    "\n",
    "    # Append the results to the dictionary\n",
    "    results.append({\n",
    "        'feature': feature,\n",
    "        'logistic_auc': log_auc,\n",
    "        'random_forest_auc': rfc_auc,\n",
    "        'lightgbm_auc': lgb_auc,\n",
    "        'xgboost_auc': xgb_auc\n",
    "    })\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# sort by best ROC-AUC score across models\n",
    "results_df['best_auc'] = results_df[['logistic_auc', 'random_forest_auc', 'lightgbm_auc', 'xgboost_auc']].max(axis=1)\n",
    "results_df = results_df.sort_values(by='best_auc', ascending=False)\n",
    "\n",
    "print(\"Top Features by ROC-AUC:\")\n",
    "print(results_df[['feature', 'best_auc']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  prism_consumer_id                                       all_balances\n",
      "0                 0  [-27.62, 1372.38, 1347.2800000000002, 847.2800...\n",
      "1                 1  [200.0, 289.0, 1096.28, 1007.28, 973.4, 773.4,...\n",
      "2                10  [-18.15, -77.72999999999999, -191.49, -208.0, ...\n",
      "3               100  [200.0, 0.0, -901.7, -1387.42, -1803.580000000...\n",
      "4              1000  [500.0, 1200.0, 700.0, 381.92, -118.0799999999...\n"
     ]
    }
   ],
   "source": [
    "# group balances as a list for each consumer\n",
    "grouped_balances = transactions_with_balances.groupby('prism_consumer_id')['calculated_balance'].apply(list).reset_index()\n",
    "grouped_balances.rename(columns={'calculated_balance': 'all_balances'}, inplace=True)\n",
    "print(grouped_balances.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  prism_consumer_id  negative_balance_count\n",
      "0                 0                     237\n",
      "1                 1                      27\n",
      "2                10                     322\n",
      "3               100                     119\n",
      "4              1000                       8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/mwcq9vv51rscfd92n_2xs8vc0000gn/T/ipykernel_11723/465156714.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  negative_balance_count = transactions_with_balances.groupby('prism_consumer_id').apply(\n"
     ]
    }
   ],
   "source": [
    "# Count how many times the calculated balance was negative for each consumer\n",
    "negative_balance_count = transactions_with_balances.groupby('prism_consumer_id').apply(\n",
    "    lambda group: (group['calculated_balance'] < 0).sum()\n",
    ").reset_index()\n",
    "\n",
    "negative_balance_count.columns = ['prism_consumer_id', 'negative_balance_count']\n",
    "print(negative_balance_count.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      prism_consumer_id  account_age_days\n",
      "0                     0               979\n",
      "1                     1              1041\n",
      "2                    10               826\n",
      "3                   100              1102\n",
      "4                  1000               461\n",
      "...                 ...               ...\n",
      "13004              9995               431\n",
      "13005              9996               208\n",
      "13006              9997               347\n",
      "13007              9998               186\n",
      "13008              9999               271\n",
      "\n",
      "[13009 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the account age in days\n",
    "\n",
    "acct['balance_date'] = pd.to_datetime(acct['balance_date'])\n",
    "acct['account_age'] = (acct['balance_date'].max() - acct['balance_date']).dt.days\n",
    "account_age = acct.groupby('prism_consumer_id')['account_age'].max().reset_index()\n",
    "account_age.columns = ['prism_consumer_id', 'account_age_days']\n",
    "print(account_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      prism_consumer_id prism_account_id account_type balance_date  balance  \\\n",
      "82                 2246               82     CHECKING   2021-04-30  -168.90   \n",
      "206                2751              206     CHECKING   2022-03-30  -474.41   \n",
      "506                2242              506     CHECKING   2022-03-31   -49.52   \n",
      "616                3280              616     CHECKING   2021-11-30    -7.23   \n",
      "904                1056              904     CHECKING   2021-03-31  -313.61   \n",
      "...                 ...              ...          ...          ...      ...   \n",
      "24239             12997            24239  CREDIT CARD   2021-12-14   -25.00   \n",
      "24279             13976            24279  CREDIT CARD   2022-02-15 -1025.27   \n",
      "24296             11678            24296     CHECKING   2021-12-19  -145.00   \n",
      "24357             10353            24357      SAVINGS   2021-12-16   -10.00   \n",
      "24426             10580            24426     CHECKING   2022-03-10   -48.69   \n",
      "\n",
      "       total_balance    month  days_account_open  account_age  \n",
      "82            221.14  2021-04               1102         1102  \n",
      "206          -473.77  2022-03                768          768  \n",
      "506          1017.26  2022-03                767          767  \n",
      "616            -7.23  2021-11                888          888  \n",
      "904            53.49  2021-03               1132         1132  \n",
      "...              ...      ...                ...          ...  \n",
      "24239       18327.23  2021-12                874          874  \n",
      "24279      574289.23  2022-02                811          811  \n",
      "24296         539.86  2021-12                869          869  \n",
      "24357         884.11  2021-12                872          872  \n",
      "24426       13592.99  2022-03                788          788  \n",
      "\n",
      "[599 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "acct['balance'] = pd.to_numeric(acct['balance'], errors='coerce')\n",
    "\n",
    "negative_balances = acct[acct['balance'] < 0]\n",
    "if negative_balances.empty:\n",
    "    print(\"No negative balances found in the dataset.\")\n",
    "else:\n",
    "    print(negative_balances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      prism_consumer_id  negative_count  total_transactions  \\\n",
      "0                     0             237                 408   \n",
      "1                     1              27                 314   \n",
      "2                    10             322                 341   \n",
      "3                   100             119                 122   \n",
      "4                  1000               8                 211   \n",
      "...                 ...             ...                 ...   \n",
      "14487              9995              95                 311   \n",
      "14488              9996              35                  42   \n",
      "14489              9997              71                 261   \n",
      "14490              9998              59                 220   \n",
      "14491              9999              25                 381   \n",
      "\n",
      "       negative_balance_ratio  \n",
      "0                    0.580882  \n",
      "1                    0.085987  \n",
      "2                    0.944282  \n",
      "3                    0.975410  \n",
      "4                    0.037915  \n",
      "...                       ...  \n",
      "14487                0.305466  \n",
      "14488                0.833333  \n",
      "14489                0.272031  \n",
      "14490                0.268182  \n",
      "14491                0.065617  \n",
      "\n",
      "[14492 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check if the balance is negative for each transaction\n",
    "transactions_with_balances['is_negative'] = transactions_with_balances['calculated_balance'] < 0\n",
    "\n",
    "# Group by prism_consumer_id and calculate:\n",
    "# 1. The count of negative balances\n",
    "# 2. The total number of transactions\n",
    "negative_balance_ratio = transactions_with_balances.groupby('prism_consumer_id').agg(\n",
    "    negative_count=('is_negative', 'sum'),  # Count of negative balances\n",
    "    total_transactions=('calculated_balance', 'size')  # Total number of transactions\n",
    ").reset_index()\n",
    "\n",
    "# Calculate the ratio of negative balances to total transactions\n",
    "negative_balance_ratio['negative_balance_ratio'] = (\n",
    "    negative_balance_ratio['negative_count'] / negative_balance_ratio['total_transactions']\n",
    ")\n",
    "\n",
    "# Fill NaN values with 0 in case of division by zero or missing data\n",
    "negative_balance_ratio.fillna(0, inplace=True)\n",
    "\n",
    "# Output the result\n",
    "print(negative_balance_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression for ['negative_balance_ratio']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.47      0.62      2784\n",
      "         1.0       0.08      0.57      0.14       216\n",
      "\n",
      "    accuracy                           0.48      3000\n",
      "   macro avg       0.51      0.52      0.38      3000\n",
      "weighted avg       0.87      0.48      0.59      3000\n",
      "\n",
      "ROC-AUC Score: 0.533\n",
      "\n",
      "Random Forest Classification for ['negative_balance_ratio']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.55      0.69      2784\n",
      "         1.0       0.07      0.42      0.12       216\n",
      "\n",
      "    accuracy                           0.54      3000\n",
      "   macro avg       0.50      0.48      0.40      3000\n",
      "weighted avg       0.86      0.54      0.65      3000\n",
      "\n",
      "ROC-AUC Score: 0.488\n",
      "[LightGBM] [Info] Number of positive: 11210, number of negative: 11210\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 22420, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "LightGBM Classification for ['negative_balance_ratio']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.52      0.67      2784\n",
      "         1.0       0.08      0.52      0.14       216\n",
      "\n",
      "    accuracy                           0.52      3000\n",
      "   macro avg       0.51      0.52      0.40      3000\n",
      "weighted avg       0.87      0.52      0.63      3000\n",
      "\n",
      "ROC-AUC Score: 0.523\n",
      "\n",
      "SVM Classification for ['negative_balance_ratio']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.22      0.36      2784\n",
      "         1.0       0.08      0.83      0.14       216\n",
      "\n",
      "    accuracy                           0.27      3000\n",
      "   macro avg       0.51      0.53      0.25      3000\n",
      "weighted avg       0.88      0.27      0.35      3000\n",
      "\n",
      "ROC-AUC Score: 0.525\n",
      "\n",
      "XGBoost Classification for ['negative_balance_ratio']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      2784\n",
      "         1.0       0.07      1.00      0.13       216\n",
      "\n",
      "    accuracy                           0.07      3000\n",
      "   macro avg       0.04      0.50      0.07      3000\n",
      "weighted avg       0.01      0.07      0.01      3000\n",
      "\n",
      "ROC-AUC Score: 0.511\n"
     ]
    }
   ],
   "source": [
    "feature_column = 'negative_balance_ratio'\n",
    "\n",
    "X = consumer_features[[feature_column]]\n",
    "y = consumer_features['DQ_TARGET']\n",
    "\n",
    "run_classification2([feature_column], 'DQ_TARGET', consumer_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/mwcq9vv51rscfd92n_2xs8vc0000gn/T/ipykernel_11723/4280441153.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outflow_features = debit_transactions.groupby('prism_consumer_id').apply(lambda group: {\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  prism_consumer_id  avg_monthly_outflow  avg_yearly_outflow\n",
      "0                 0          2129.772857           14908.410\n",
      "1                 1          3299.767143           23098.370\n",
      "2                10          3109.514286           10883.300\n",
      "3               100          6623.768333           19871.305\n",
      "4              1000         11130.712857           38957.495\n"
     ]
    }
   ],
   "source": [
    "debit_transactions = transactions[transactions['credit_or_debit'] == 'DEBIT']\n",
    "\n",
    "# Calculate monthly and yearly outflows per consumer\n",
    "outflow_features = debit_transactions.groupby('prism_consumer_id').apply(lambda group: {\n",
    "    'avg_monthly_outflow': group['amount'].sum() / max(1, group['posted_date'].dt.to_period('M').nunique()),  # Avoid division by zero\n",
    "    'avg_yearly_outflow': group['amount'].sum() / max(1, group['posted_date'].dt.to_period('Y').nunique())   # Avoid division by zero\n",
    "}).apply(pd.Series).reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "outflow_features.columns = ['prism_consumer_id', 'avg_monthly_outflow', 'avg_yearly_outflow']\n",
    "\n",
    "# Display the resulting outflow features\n",
    "print(outflow_features.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/mwcq9vv51rscfd92n_2xs8vc0000gn/T/ipykernel_11723/1327682312.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  category_features = transactions.groupby(['prism_consumer_id', 'category']).apply(lambda group: {\n"
     ]
    }
   ],
   "source": [
    "# Calculate total transactions (count and sum) by category\n",
    "category_features = transactions.groupby(['prism_consumer_id', 'category']).apply(lambda group: {\n",
    "    'total_transactions': len(group),\n",
    "    'total_credit_amount': group[group['credit_or_debit'] == 'CREDIT']['amount'].sum(),\n",
    "    'total_debit_amount': group[group['credit_or_debit'] == 'DEBIT']['amount'].sum(),\n",
    "    'total_transaction_amount': group['amount'].sum()\n",
    "}).apply(pd.Series).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_account_id</th>\n",
       "      <th>account_type</th>\n",
       "      <th>balance_date</th>\n",
       "      <th>balance</th>\n",
       "      <th>days_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3023</td>\n",
       "      <td>0</td>\n",
       "      <td>SAVINGS</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>90.57</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3023</td>\n",
       "      <td>1</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>225.95</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4416</td>\n",
       "      <td>2</td>\n",
       "      <td>SAVINGS</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>15157.17</td>\n",
       "      <td>767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4416</td>\n",
       "      <td>3</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>66.42</td>\n",
       "      <td>767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4227</td>\n",
       "      <td>4</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>7042.90</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24461</th>\n",
       "      <td>11500</td>\n",
       "      <td>24461</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2022-03-27</td>\n",
       "      <td>732.75</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24462</th>\n",
       "      <td>11615</td>\n",
       "      <td>24462</td>\n",
       "      <td>SAVINGS</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>5.00</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24463</th>\n",
       "      <td>11615</td>\n",
       "      <td>24463</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>1956.46</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24464</th>\n",
       "      <td>12210</td>\n",
       "      <td>24464</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2022-03-28</td>\n",
       "      <td>2701.51</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24465</th>\n",
       "      <td>11615</td>\n",
       "      <td>24465</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>7967.45</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24466 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prism_consumer_id prism_account_id account_type balance_date   balance  \\\n",
       "0                  3023                0      SAVINGS   2021-08-31     90.57   \n",
       "1                  3023                1     CHECKING   2021-08-31    225.95   \n",
       "2                  4416                2      SAVINGS   2022-03-31  15157.17   \n",
       "3                  4416                3     CHECKING   2022-03-31     66.42   \n",
       "4                  4227                4     CHECKING   2021-07-31   7042.90   \n",
       "...                 ...              ...          ...          ...       ...   \n",
       "24461             11500            24461     CHECKING   2022-03-27    732.75   \n",
       "24462             11615            24462      SAVINGS   2022-03-30      5.00   \n",
       "24463             11615            24463     CHECKING   2022-03-30   1956.46   \n",
       "24464             12210            24464     CHECKING   2022-03-28   2701.51   \n",
       "24465             11615            24465     CHECKING   2022-03-30   7967.45   \n",
       "\n",
       "       days_since  \n",
       "0             979  \n",
       "1             979  \n",
       "2             767  \n",
       "3             767  \n",
       "4            1010  \n",
       "...           ...  \n",
       "24461         771  \n",
       "24462         768  \n",
       "24463         768  \n",
       "24464         770  \n",
       "24465         768  \n",
       "\n",
       "[24466 rows x 6 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>today_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>294.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3211.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>91.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24087</th>\n",
       "      <td>9995</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24088</th>\n",
       "      <td>9996</td>\n",
       "      <td>252.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24089</th>\n",
       "      <td>9997</td>\n",
       "      <td>611.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24090</th>\n",
       "      <td>9998</td>\n",
       "      <td>-862.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24091</th>\n",
       "      <td>9999</td>\n",
       "      <td>-9.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24092 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prism_consumer_id  today_balance\n",
       "0                     0          25.70\n",
       "1                     0         294.67\n",
       "2                     1        3211.18\n",
       "3                     1          91.24\n",
       "4                    10           1.49\n",
       "...                 ...            ...\n",
       "24087              9995           0.00\n",
       "24088              9996         252.67\n",
       "24089              9997         611.28\n",
       "24090              9998        -862.99\n",
       "24091              9999          -9.02\n",
       "\n",
       "[24092 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>avg_balance_30d</th>\n",
       "      <th>avg_balance_90d</th>\n",
       "      <th>avg_balance_180d</th>\n",
       "      <th>avg_balance_365d</th>\n",
       "      <th>below_25_30d</th>\n",
       "      <th>below_25_90d</th>\n",
       "      <th>below_25_180d</th>\n",
       "      <th>below_25_365d</th>\n",
       "      <th>below_50_30d</th>\n",
       "      <th>below_50_90d</th>\n",
       "      <th>below_50_180d</th>\n",
       "      <th>below_50_365d</th>\n",
       "      <th>below_100_30d</th>\n",
       "      <th>below_100_90d</th>\n",
       "      <th>below_100_180d</th>\n",
       "      <th>below_100_365d</th>\n",
       "      <th>days_negative_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13004</th>\n",
       "      <td>9995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13005</th>\n",
       "      <td>9996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13006</th>\n",
       "      <td>9997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>611.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13007</th>\n",
       "      <td>9998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-862.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13008</th>\n",
       "      <td>9999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13009 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prism_consumer_id  avg_balance_30d  avg_balance_90d  avg_balance_180d  \\\n",
       "0                     0              0.0              0.0               0.0   \n",
       "1                     1              0.0              0.0               0.0   \n",
       "2                    10              0.0              0.0               0.0   \n",
       "3                   100              0.0              0.0               0.0   \n",
       "4                  1000              0.0              0.0               0.0   \n",
       "...                 ...              ...              ...               ...   \n",
       "13004              9995              0.0              0.0               0.0   \n",
       "13005              9996              0.0              0.0               0.0   \n",
       "13006              9997              0.0              0.0               0.0   \n",
       "13007              9998              0.0              0.0               0.0   \n",
       "13008              9999              0.0              0.0               0.0   \n",
       "\n",
       "       avg_balance_365d  below_25_30d  below_25_90d  below_25_180d  \\\n",
       "0                  0.00           0.0           0.0            0.0   \n",
       "1                  0.00           0.0           0.0            0.0   \n",
       "2                  0.00           0.0           0.0            0.0   \n",
       "3                  0.00           0.0           0.0            0.0   \n",
       "4                  0.00           0.0           0.0            0.0   \n",
       "...                 ...           ...           ...            ...   \n",
       "13004              0.00           0.0           0.0            0.0   \n",
       "13005            252.67           0.0           0.0            0.0   \n",
       "13006            611.28           0.0           0.0            0.0   \n",
       "13007           -862.99           0.0           0.0            0.0   \n",
       "13008             -9.02           0.0           0.0            0.0   \n",
       "\n",
       "       below_25_365d  below_50_30d  below_50_90d  below_50_180d  \\\n",
       "0                0.0           0.0           0.0            0.0   \n",
       "1                0.0           0.0           0.0            0.0   \n",
       "2                0.0           0.0           0.0            0.0   \n",
       "3                0.0           0.0           0.0            0.0   \n",
       "4                0.0           0.0           0.0            0.0   \n",
       "...              ...           ...           ...            ...   \n",
       "13004            0.0           0.0           0.0            0.0   \n",
       "13005            0.0           0.0           0.0            0.0   \n",
       "13006            0.0           0.0           0.0            0.0   \n",
       "13007            1.0           0.0           0.0            0.0   \n",
       "13008            1.0           0.0           0.0            0.0   \n",
       "\n",
       "       below_50_365d  below_100_30d  below_100_90d  below_100_180d  \\\n",
       "0                0.0            0.0            0.0             0.0   \n",
       "1                0.0            0.0            0.0             0.0   \n",
       "2                0.0            0.0            0.0             0.0   \n",
       "3                0.0            0.0            0.0             0.0   \n",
       "4                0.0            0.0            0.0             0.0   \n",
       "...              ...            ...            ...             ...   \n",
       "13004            0.0            0.0            0.0             0.0   \n",
       "13005            0.0            0.0            0.0             0.0   \n",
       "13006            0.0            0.0            0.0             0.0   \n",
       "13007            1.0            0.0            0.0             0.0   \n",
       "13008            1.0            0.0            0.0             0.0   \n",
       "\n",
       "       below_100_365d  days_negative_balance  \n",
       "0                 0.0                    0.0  \n",
       "1                 0.0                    0.0  \n",
       "2                 0.0                    0.0  \n",
       "3                 0.0                    0.0  \n",
       "4                 0.0                    0.0  \n",
       "...               ...                    ...  \n",
       "13004             0.0                    0.0  \n",
       "13005             0.0                    0.0  \n",
       "13006             0.0                    0.0  \n",
       "13007             1.0                    1.0  \n",
       "13008             1.0                    1.0  \n",
       "\n",
       "[13009 rows x 18 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "acct['balance_date'] = pd.to_datetime(acct['balance_date'], errors='coerce')\n",
    "print(acct['balance_date'].isna().sum())  # Check for NaT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/mwcq9vv51rscfd92n_2xs8vc0000gn/T/ipykernel_11723/235641726.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  balance_features = acct.groupby('prism_consumer_id').apply(lambda group: {\n"
     ]
    }
   ],
   "source": [
    "balance_features = acct.groupby('prism_consumer_id').apply(lambda group: {\n",
    "    **{f'avg_balance_{tw}d': group[group['days_since'] <= tw]['balance'].mean() if not group[group['days_since'] <= tw].empty else 0 for tw in time_windows},\n",
    "    **{f'below_{threshold}_{tw}d': (group[group['days_since'] <= tw]['balance'] < threshold).sum() for threshold in [25, 50, 100] for tw in time_windows},\n",
    "    **{'days_negative_balance': (group['balance'] < 0).sum()}\n",
    "}).apply(pd.Series).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ids = set(consumer['prism_consumer_id']) - set(acct['prism_consumer_id'])\n",
    "print(f\"Missing IDs: {missing_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/mwcq9vv51rscfd92n_2xs8vc0000gn/T/ipykernel_11723/1935909462.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negative_ratio[['negative_balance_days', 'negative_balance_ratio']].fillna(0, inplace=True)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['negative_balance_days', 'negative_balance_ratio'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m consumer \u001b[38;5;241m=\u001b[39m consumer\u001b[38;5;241m.\u001b[39mmerge(negative_ratio[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprism_consumer_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative_balance_days\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdays_open\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative_balance_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m]], on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprism_consumer_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Fill NaN values with 0 for consumers with no transactions\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mconsumer\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnegative_balance_days\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdays_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnegative_balance_ratio\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Final Output\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsumer dataset with negative balance ratio and related columns added: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconsumer\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['negative_balance_days', 'negative_balance_ratio'] not in index\""
     ]
    }
   ],
   "source": [
    "# Ensure dates are in datetime format\n",
    "transactions['posted_date'] = pd.to_datetime(transactions['posted_date'])\n",
    "acct['balance_date'] = pd.to_datetime(acct['balance_date'])\n",
    "\n",
    "# Step 1: Calculate cumulative daily balance for each consumer\n",
    "transactions['amount_adjusted'] = transactions.apply(\n",
    "    lambda x: x['amount'] if x['credit_or_debit'] == 'CREDIT' else -x['amount'], axis=1\n",
    ")\n",
    "\n",
    "# Group by consumer and date, calculate daily balance\n",
    "daily_balance = transactions.groupby(['prism_consumer_id', 'posted_date'])['amount_adjusted'].sum().reset_index()\n",
    "daily_balance['cumulative_balance'] = daily_balance.groupby('prism_consumer_id')['amount_adjusted'].cumsum()\n",
    "\n",
    "# Step 2: Count negative balance days\n",
    "negative_balance_days = daily_balance[daily_balance['cumulative_balance'] < 0].groupby('prism_consumer_id').size().reset_index(name='negative_balance_days')\n",
    "\n",
    "# Step 3: Calculate account open duration (in days)\n",
    "first_transaction_date = transactions.groupby('prism_consumer_id')['posted_date'].min().reset_index().rename(columns={'posted_date': 'first_transaction_date'})\n",
    "first_transaction_date['days_open'] = (pd.Timestamp.today() - first_transaction_date['first_transaction_date']).dt.days\n",
    "\n",
    "# Step 4: Merge negative balance days and account open duration\n",
    "negative_ratio = negative_balance_days.merge(first_transaction_date, on='prism_consumer_id', how='left')\n",
    "negative_ratio['negative_balance_ratio'] = negative_ratio['negative_balance_days'] / negative_ratio['days_open']\n",
    "\n",
    "# Fill missing values for consumers with no negative balance days\n",
    "negative_ratio[['negative_balance_days', 'negative_balance_ratio']].fillna(0, inplace=True)\n",
    "\n",
    "# Step 5: Merge with the main consumer dataset\n",
    "consumer = consumer.merge(negative_ratio[['prism_consumer_id', 'negative_balance_days', 'days_open', 'negative_balance_ratio']], on='prism_consumer_id', how='left')\n",
    "\n",
    "# Fill NaN values with 0 for consumers with no transactions\n",
    "consumer[['negative_balance_days', 'days_open', 'negative_balance_ratio']].fillna(0, inplace=True)\n",
    "\n",
    "# Final Output\n",
    "print(f\"Consumer dataset with negative balance ratio and related columns added: {consumer.shape}\")\n",
    "consumer.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>negative_balance_days</th>\n",
       "      <th>first_transaction_date</th>\n",
       "      <th>days_open</th>\n",
       "      <th>negative_balance_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>1410</td>\n",
       "      <td>0.056738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>1470</td>\n",
       "      <td>0.006803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>130</td>\n",
       "      <td>2021-08-17</td>\n",
       "      <td>1256</td>\n",
       "      <td>0.103503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>54</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>907</td>\n",
       "      <td>0.059537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>877</td>\n",
       "      <td>0.009122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12781</th>\n",
       "      <td>9995</td>\n",
       "      <td>36</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>781</td>\n",
       "      <td>0.046095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12782</th>\n",
       "      <td>9996</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-07-21</td>\n",
       "      <td>553</td>\n",
       "      <td>0.045208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12783</th>\n",
       "      <td>9997</td>\n",
       "      <td>19</td>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>697</td>\n",
       "      <td>0.027260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12784</th>\n",
       "      <td>9998</td>\n",
       "      <td>21</td>\n",
       "      <td>2023-08-07</td>\n",
       "      <td>536</td>\n",
       "      <td>0.039179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12785</th>\n",
       "      <td>9999</td>\n",
       "      <td>11</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>623</td>\n",
       "      <td>0.017657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12786 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prism_consumer_id  negative_balance_days first_transaction_date  \\\n",
       "0                     0                     80             2021-03-16   \n",
       "1                     1                     10             2021-01-15   \n",
       "2                    10                    130             2021-08-17   \n",
       "3                   100                     54             2022-08-01   \n",
       "4                  1000                      8             2022-08-31   \n",
       "...                 ...                    ...                    ...   \n",
       "12781              9995                     36             2022-12-05   \n",
       "12782              9996                     25             2023-07-21   \n",
       "12783              9997                     19             2023-02-27   \n",
       "12784              9998                     21             2023-08-07   \n",
       "12785              9999                     11             2023-05-12   \n",
       "\n",
       "       days_open  negative_balance_ratio  \n",
       "0           1410                0.056738  \n",
       "1           1470                0.006803  \n",
       "2           1256                0.103503  \n",
       "3            907                0.059537  \n",
       "4            877                0.009122  \n",
       "...          ...                     ...  \n",
       "12781        781                0.046095  \n",
       "12782        553                0.045208  \n",
       "12783        697                0.027260  \n",
       "12784        536                0.039179  \n",
       "12785        623                0.017657  \n",
       "\n",
       "[12786 rows x 5 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['days_open'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m consumer \u001b[38;5;241m=\u001b[39m consumer\u001b[38;5;241m.\u001b[39mmerge(negative_ratio[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprism_consumer_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative_balance_days\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdays_open\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative_balance_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m]], on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprism_consumer_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Fill NaN values for consumers with no transactions\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m consumer[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative_balance_days\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdays_open\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative_balance_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mconsumer\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnegative_balance_days\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdays_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnegative_balance_ratio\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Final Output\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsumer dataset with negative balance ratio and related columns added: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconsumer\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['days_open'] not in index\""
     ]
    }
   ],
   "source": [
    "# Ensure dates are in datetime format\n",
    "transactions['posted_date'] = pd.to_datetime(transactions['posted_date'])\n",
    "acct['balance_date'] = pd.to_datetime(acct['balance_date'])\n",
    "\n",
    "# Step 1: Calculate cumulative daily balance for each consumer\n",
    "transactions['amount_adjusted'] = transactions.apply(\n",
    "    lambda x: x['amount'] if x['credit_or_debit'] == 'CREDIT' else -x['amount'], axis=1\n",
    ")\n",
    "\n",
    "# Group by consumer and date, calculate daily balance\n",
    "daily_balance = transactions.groupby(['prism_consumer_id', 'posted_date'])['amount_adjusted'].sum().reset_index()\n",
    "daily_balance['cumulative_balance'] = daily_balance.groupby('prism_consumer_id')['amount_adjusted'].cumsum()\n",
    "\n",
    "# Step 2: Count negative balance days\n",
    "negative_balance_days = daily_balance[daily_balance['cumulative_balance'] < 0].groupby('prism_consumer_id').size().reset_index(name='negative_balance_days')\n",
    "\n",
    "# Step 3: Calculate account open duration (in days)\n",
    "first_transaction_date = transactions.groupby('prism_consumer_id')['posted_date'].min().reset_index().rename(columns={'posted_date': 'first_transaction_date'})\n",
    "first_transaction_date['days_open'] = (pd.Timestamp.today() - first_transaction_date['first_transaction_date']).dt.days\n",
    "\n",
    "# Step 4: Merge negative balance days and account open duration\n",
    "# Left join to ensure all consumers are included\n",
    "negative_ratio = first_transaction_date.merge(negative_balance_days, on='prism_consumer_id', how='left')\n",
    "\n",
    "# Fill missing values for consumers with no negative balance days\n",
    "negative_ratio['negative_balance_days'] = negative_ratio['negative_balance_days'].fillna(0)\n",
    "\n",
    "# Calculate the ratio of negative balance days to account open duration\n",
    "negative_ratio['negative_balance_ratio'] = negative_ratio['negative_balance_days'] / negative_ratio['days_open']\n",
    "\n",
    "# Step 5: Merge with the main consumer dataset\n",
    "consumer = consumer.merge(negative_ratio[['prism_consumer_id', 'negative_balance_days', 'days_open', 'negative_balance_ratio']], on='prism_consumer_id', how='left')\n",
    "\n",
    "# Fill NaN values for consumers with no transactions\n",
    "consumer[['negative_balance_days', 'days_open', 'negative_balance_ratio']] = consumer[['negative_balance_days', 'days_open', 'negative_balance_ratio']].fillna(0)\n",
    "\n",
    "# Final Output\n",
    "print(f\"Consumer dataset with negative balance ratio and related columns added: {consumer.shape}\")\n",
    "consumer.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/mwcq9vv51rscfd92n_2xs8vc0000gn/T/ipykernel_11723/3584599517.py:24: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  transactions_with_balances = transactions.groupby('prism_consumer_id').apply(calculate_balances)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_transaction_id</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>credit_or_debit</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>inflow</th>\n",
       "      <th>outflow</th>\n",
       "      <th>is_negative_balance</th>\n",
       "      <th>is_high_balance</th>\n",
       "      <th>month</th>\n",
       "      <th>amount_adjusted</th>\n",
       "      <th>calculated_balance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>136802</th>\n",
       "      <td>0</td>\n",
       "      <td>136738</td>\n",
       "      <td>14</td>\n",
       "      <td>27.62</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-03</td>\n",
       "      <td>-27.62</td>\n",
       "      <td>-27.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136767</th>\n",
       "      <td>0</td>\n",
       "      <td>136703</td>\n",
       "      <td>11</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-03</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>1372.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136803</th>\n",
       "      <td>0</td>\n",
       "      <td>136739</td>\n",
       "      <td>39</td>\n",
       "      <td>25.10</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-03</td>\n",
       "      <td>-25.10</td>\n",
       "      <td>1347.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136804</th>\n",
       "      <td>0</td>\n",
       "      <td>136740</td>\n",
       "      <td>37</td>\n",
       "      <td>500.00</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-03</td>\n",
       "      <td>-500.00</td>\n",
       "      <td>847.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136805</th>\n",
       "      <td>0</td>\n",
       "      <td>136741</td>\n",
       "      <td>14</td>\n",
       "      <td>25.00</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2021-03-18</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-03</td>\n",
       "      <td>-25.00</td>\n",
       "      <td>822.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">9999</th>\n",
       "      <th>1524647</th>\n",
       "      <td>9999</td>\n",
       "      <td>1522635</td>\n",
       "      <td>16</td>\n",
       "      <td>66.63</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-08</td>\n",
       "      <td>-66.63</td>\n",
       "      <td>-274.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524648</th>\n",
       "      <td>9999</td>\n",
       "      <td>1522636</td>\n",
       "      <td>14</td>\n",
       "      <td>16.91</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-08</td>\n",
       "      <td>-16.91</td>\n",
       "      <td>-290.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524649</th>\n",
       "      <td>9999</td>\n",
       "      <td>1522637</td>\n",
       "      <td>14</td>\n",
       "      <td>3.52</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-08</td>\n",
       "      <td>-3.52</td>\n",
       "      <td>-294.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524650</th>\n",
       "      <td>9999</td>\n",
       "      <td>1522638</td>\n",
       "      <td>16</td>\n",
       "      <td>7.99</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-08</td>\n",
       "      <td>-7.99</td>\n",
       "      <td>-302.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524651</th>\n",
       "      <td>9999</td>\n",
       "      <td>1522639</td>\n",
       "      <td>16</td>\n",
       "      <td>16.99</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-08</td>\n",
       "      <td>-16.99</td>\n",
       "      <td>-319.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6407321 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          prism_consumer_id prism_transaction_id  category  \\\n",
       "prism_consumer_id                                                            \n",
       "0                 136802                  0               136738        14   \n",
       "                  136767                  0               136703        11   \n",
       "                  136803                  0               136739        39   \n",
       "                  136804                  0               136740        37   \n",
       "                  136805                  0               136741        14   \n",
       "...                                     ...                  ...       ...   \n",
       "9999              1524647              9999              1522635        16   \n",
       "                  1524648              9999              1522636        14   \n",
       "                  1524649              9999              1522637        14   \n",
       "                  1524650              9999              1522638        16   \n",
       "                  1524651              9999              1522639        16   \n",
       "\n",
       "                            amount credit_or_debit posted_date  inflow  \\\n",
       "prism_consumer_id                                                        \n",
       "0                 136802     27.62           DEBIT  2021-03-16   False   \n",
       "                  136767   1400.00          CREDIT  2021-03-17    True   \n",
       "                  136803     25.10           DEBIT  2021-03-17   False   \n",
       "                  136804    500.00           DEBIT  2021-03-17   False   \n",
       "                  136805     25.00           DEBIT  2021-03-18   False   \n",
       "...                            ...             ...         ...     ...   \n",
       "9999              1524647    66.63           DEBIT  2023-08-08   False   \n",
       "                  1524648    16.91           DEBIT  2023-08-08   False   \n",
       "                  1524649     3.52           DEBIT  2023-08-08   False   \n",
       "                  1524650     7.99           DEBIT  2023-08-08   False   \n",
       "                  1524651    16.99           DEBIT  2023-08-08   False   \n",
       "\n",
       "                           outflow  is_negative_balance  is_high_balance  \\\n",
       "prism_consumer_id                                                          \n",
       "0                 136802      True                False            False   \n",
       "                  136767     False                False             True   \n",
       "                  136803      True                False            False   \n",
       "                  136804      True                False            False   \n",
       "                  136805      True                False            False   \n",
       "...                            ...                  ...              ...   \n",
       "9999              1524647     True                False            False   \n",
       "                  1524648     True                False            False   \n",
       "                  1524649     True                False            False   \n",
       "                  1524650     True                False            False   \n",
       "                  1524651     True                False            False   \n",
       "\n",
       "                             month  amount_adjusted  calculated_balance  \n",
       "prism_consumer_id                                                        \n",
       "0                 136802   2021-03           -27.62              -27.62  \n",
       "                  136767   2021-03          1400.00             1372.38  \n",
       "                  136803   2021-03           -25.10             1347.28  \n",
       "                  136804   2021-03          -500.00              847.28  \n",
       "                  136805   2021-03           -25.00              822.28  \n",
       "...                            ...              ...                 ...  \n",
       "9999              1524647  2023-08           -66.63             -274.02  \n",
       "                  1524648  2023-08           -16.91             -290.93  \n",
       "                  1524649  2023-08            -3.52             -294.45  \n",
       "                  1524650  2023-08            -7.99             -302.44  \n",
       "                  1524651  2023-08           -16.99             -319.43  \n",
       "\n",
       "[6407321 rows x 13 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure 'posted_date' is in datetime format for proper sorting\n",
    "transactions['posted_date'] = pd.to_datetime(transactions['posted_date'])\n",
    "\n",
    "# Sort transactions by consumer ID and date\n",
    "transactions = transactions.sort_values(by=['prism_consumer_id', 'posted_date'])\n",
    "\n",
    "# Function to calculate balances\n",
    "def calculate_balances(group):\n",
    "    # Start with an initial balance of 0\n",
    "    balance = 0\n",
    "    balances = []  # List to hold cumulative balances\n",
    "    for _, row in group.iterrows():\n",
    "        if row['credit_or_debit'] == 'CREDIT':\n",
    "            balance += row['amount']  # Add for CREDIT\n",
    "        elif row['credit_or_debit'] == 'DEBIT':\n",
    "            balance -= row['amount']  # Subtract for DEBIT\n",
    "        balances.append(balance)\n",
    "    group['calculated_balance'] = balances\n",
    "    return group\n",
    "\n",
    "# Apply the function to each consumer group\n",
    "transactions_with_balances = transactions.groupby('prism_consumer_id').apply(calculate_balances)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "transactions_with_balances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/mwcq9vv51rscfd92n_2xs8vc0000gn/T/ipykernel_11723/938016773.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  transaction_features = transactions.groupby('prism_consumer_id').apply(lambda group: {\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  prism_consumer_id evaluation_date  credit_score  DQ_TARGET  total_balance  \\\n",
      "0                 0      2021-09-01         726.0        0.0         320.37   \n",
      "1                 1      2021-07-01         626.0        0.0        3302.42   \n",
      "2                 2      2021-05-01         680.0        0.0        2805.36   \n",
      "3                 3      2021-03-01         734.0        0.0        7667.01   \n",
      "4                 4      2021-10-01         676.0        0.0         394.55   \n",
      "\n",
      "   latest_balance  avg_balance_12m  avg_balance_9m  avg_balance_6m  \\\n",
      "0           25.70              0.0             0.0             0.0   \n",
      "1         3211.18              0.0             0.0             0.0   \n",
      "2         2561.43              0.0             0.0             0.0   \n",
      "3         6690.19              0.0             0.0             0.0   \n",
      "4          391.62              0.0             0.0             0.0   \n",
      "\n",
      "   days_since_open  ...  category_32_spending  category_48_spending  \\\n",
      "0           1242.0  ...                   0.0                   0.0   \n",
      "1           1304.0  ...                   0.0                   0.0   \n",
      "2           1365.0  ...                   0.0                   0.0   \n",
      "3           1426.0  ...                   0.0                   0.0   \n",
      "4           1485.0  ...                   0.0                   0.0   \n",
      "\n",
      "   category_29_spending  category_38_spending  category_9_spending  \\\n",
      "0                  0.00                   0.0                  0.0   \n",
      "1                  0.00                   0.0                  0.0   \n",
      "2                  8.57                   0.0                  0.0   \n",
      "3                  0.00                   0.0               5700.0   \n",
      "4                 23.97                   0.0              12020.0   \n",
      "\n",
      "   category_33_spending  category_43_spending  category_49_spending  \\\n",
      "0                   0.0                   0.0                   0.0   \n",
      "1                   0.0                   0.0                   0.0   \n",
      "2                   0.0                   0.0                   0.0   \n",
      "3                   0.0                   0.0                   0.0   \n",
      "4                   0.0                   0.0                   0.0   \n",
      "\n",
      "   category_44_spending  category_47_spending  \n",
      "0                   0.0                   0.0  \n",
      "1                   0.0                   0.0  \n",
      "2                   0.0                   0.0  \n",
      "3                   0.0                   0.0  \n",
      "4                   0.0                   0.0  \n",
      "\n",
      "[5 rows x 133 columns]\n",
      "  prism_consumer_id  all_balances\n",
      "0                 0         25.70\n",
      "1                 1         91.24\n",
      "2                10          1.49\n",
      "3               100        802.40\n",
      "4              1000          0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/mwcq9vv51rscfd92n_2xs8vc0000gn/T/ipykernel_11723/938016773.py:65: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  negative_balance_ratio = acct.groupby('prism_consumer_id').apply(lambda group: {\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  prism_consumer_id  negative_balance_days  days_account_open  \\\n",
      "0                 0                    0.0                0.0   \n",
      "1                 1                    0.0                0.0   \n",
      "2                10                    0.0                0.0   \n",
      "3               100                    0.0              610.0   \n",
      "4              1000                    0.0                0.0   \n",
      "\n",
      "   negative_balance_ratio  \n",
      "0                     0.0  \n",
      "1                     0.0  \n",
      "2                     0.0  \n",
      "3                     0.0  \n",
      "4                     0.0  \n"
     ]
    },
    {
     "ename": "MergeError",
     "evalue": "Passing 'suffixes' which cause duplicate columns {'negative_balance_days_x', 'negative_balance_ratio_x'} is not allowed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 75\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Merge grouped balances and negative balance ratio with consumer features\u001b[39;00m\n\u001b[1;32m     74\u001b[0m final_consumer_features \u001b[38;5;241m=\u001b[39m consumer_features\u001b[38;5;241m.\u001b[39mmerge(grouped_balances, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprism_consumer_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m final_consumer_features \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_consumer_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnegative_balance_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprism_consumer_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Fill NaN values with 0\u001b[39;00m\n\u001b[1;32m     78\u001b[0m final_consumer_features\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:10832\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10813\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m  10814\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m  10815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10828\u001b[0m     validate: MergeValidate \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m  10829\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m  10830\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m> 10832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10833\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10841\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10842\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10846\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/reshape/merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    171\u001b[0m         left_df,\n\u001b[1;32m    172\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    183\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/reshape/merge.py:888\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m    886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[0;32m--> 888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/reshape/merge.py:840\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[0;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[1;32m    837\u001b[0m left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft[:]\n\u001b[1;32m    838\u001b[0m right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright[:]\n\u001b[0;32m--> 840\u001b[0m llabels, rlabels \u001b[38;5;241m=\u001b[39m \u001b[43m_items_overlap_with_suffix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuffixes\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;66;03m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;66;03m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     lmgr \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    849\u001b[0m         join_index,\n\u001b[1;32m    850\u001b[0m         left_indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    855\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    856\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/reshape/merge.py:2757\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2755\u001b[0m     dups\u001b[38;5;241m.\u001b[39mextend(rlabels[(rlabels\u001b[38;5;241m.\u001b[39mduplicated()) \u001b[38;5;241m&\u001b[39m (\u001b[38;5;241m~\u001b[39mright\u001b[38;5;241m.\u001b[39mduplicated())]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m   2756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dups:\n\u001b[0;32m-> 2757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[1;32m   2758\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuffixes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m which cause duplicate columns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m(dups)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2759\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot allowed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2760\u001b[0m     )\n\u001b[1;32m   2762\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m llabels, rlabels\n",
      "\u001b[0;31mMergeError\u001b[0m: Passing 'suffixes' which cause duplicate columns {'negative_balance_days_x', 'negative_balance_ratio_x'} is not allowed."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure posted_date is in datetime format\n",
    "transactions['posted_date'] = pd.to_datetime(transactions['posted_date'], errors='coerce')\n",
    "\n",
    "# Calculate days since the most recent transaction for each consumer\n",
    "transactions['days_since'] = (transactions['posted_date'].max() - transactions['posted_date']).dt.days\n",
    "\n",
    "# Define time windows for spending behavior\n",
    "time_windows = [0, 350, 700, 1050, 1401]\n",
    "\n",
    "# Feature engineering based on transactions\n",
    "transaction_features = transactions.groupby('prism_consumer_id').apply(lambda group: {\n",
    "    # Total inflow (CREDIT) and outflow (DEBIT)\n",
    "    'total_credit': group[group['credit_or_debit'] == 'CREDIT']['amount'].sum(),\n",
    "    'total_debit': group[group['credit_or_debit'] == 'DEBIT']['amount'].sum(),\n",
    "    # Net transaction balance\n",
    "    'net_transaction_balance': group[group['credit_or_debit'] == 'CREDIT']['amount'].sum() - group[group['credit_or_debit'] == 'DEBIT']['amount'].sum(),\n",
    "    # Spending in different time windows\n",
    "    **{f'spending_last_{tw}_days': group[group['days_since'] <= tw]['amount'].sum() for tw in time_windows},\n",
    "    # Spending grouped by categories\n",
    "    **{f'category_{cat}_spending': group[group['category'] == cat]['amount'].sum() for cat in transactions['category'].unique()},\n",
    "}).apply(pd.Series).reset_index()\n",
    "\n",
    "# Merge transaction features with consumer data\n",
    "consumer_features = consumer.merge(transaction_features, on='prism_consumer_id', how='left')\n",
    "\n",
    "# Fill NaN values with 0 for consumers with no transactions\n",
    "consumer_features.fillna(0, inplace=True)\n",
    "\n",
    "# Check the result\n",
    "print(consumer_features.head())\n",
    "\n",
    "# Group by 'prism_consumer_id' and aggregate balance information\n",
    "grouped_balances = acct.groupby('prism_consumer_id').agg({\n",
    "    # List of all balances\n",
    "    'balance': lambda x: list(x),\n",
    "    # Count of negative balances\n",
    "    'balance': lambda x: (np.array(x) < 0).sum(),\n",
    "    # Average balance\n",
    "    'balance': 'mean',\n",
    "    # Max balance\n",
    "    'balance': 'max',\n",
    "    # Min balance\n",
    "    'balance': 'min'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "grouped_balances.rename(columns={\n",
    "    'balance': 'all_balances',\n",
    "    '<lambda_0>': 'negative_balance_count',\n",
    "    '<lambda_1>': 'average_balance',\n",
    "    '<lambda_2>': 'max_balance',\n",
    "    '<lambda_3>': 'min_balance'\n",
    "}, inplace=True)\n",
    "\n",
    "print(grouped_balances.head())\n",
    "\n",
    "# Calculate how long each account has been open\n",
    "acct['balance_date'] = pd.to_datetime(acct['balance_date'], errors='coerce')\n",
    "acct['days_account_open'] = (acct['balance_date'].max() - acct['balance_date']).dt.days\n",
    "\n",
    "# Add ratio of negative balance count to account age\n",
    "negative_balance_ratio = acct.groupby('prism_consumer_id').apply(lambda group: {\n",
    "    'negative_balance_days': (group['balance'] < 0).sum(),\n",
    "    'days_account_open': (group['balance_date'].max() - group['balance_date'].min()).days,\n",
    "    'negative_balance_ratio': (group['balance'] < 0).sum() / ((group['balance_date'].max() - group['balance_date'].min()).days + 1)\n",
    "}).apply(pd.Series).reset_index()\n",
    "\n",
    "print(negative_balance_ratio.head())\n",
    "\n",
    "# Merge grouped balances and negative balance ratio with consumer features\n",
    "final_consumer_features = consumer_features.merge(grouped_balances, on='prism_consumer_id', how='left')\n",
    "final_consumer_features = final_consumer_features.merge(negative_balance_ratio, on='prism_consumer_id', how='left')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "final_consumer_features.fillna(0, inplace=True)\n",
    "\n",
    "# Final dataframe\n",
    "print(final_consumer_features.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
